\section{Related Work}
\label{sec:related}

To our knowledge, ours is the first work to consider automated code
refactorings in the context of the PGAS model.  However,
a number of IDEs and
tools have been developed to aid parallel language users. 
We elide discussion here of automatic parallelization
techniques and parallel program analysis to focus on
related work in tooling support. Such tooling support is crucial since complete
automatic parallelization of programs is now generally regarded as infeasible.
Thus, refactoring and transformation tools allow programmers to remain aware
of, and control to a certain degree, the level of concurrency in their
code.

The SUIF Explorer~\cite{Liao99}, for the SUIF compiler
system~\cite{SUIF}, combines automatic parallelization techniques with a
dynamic dependence analyzer to assist programmers in parallelizing their
code, but does not feature integrated refactoring support.
The ParaScope Editor~\cite{Kennedy91,Hall93} is an IDE that
enables exploration and manipulation of
loop-level parallelism in a Fortran-like language. It makes
analysis results and a number of program transformations, including {\em loop
interchange} and {\em loop distribution}, available to the user.

Photran~\cite{Overbey05} is an IDE that intends to, but does not yet, 
provide concurrency refactoring support for HPC applications in Fortran.
TSF~\cite{TSF} is an IDE tool for writing
transformation scripts and transforming parallel Fortran programs. Some of
the transformations it provides have preconditions for verifying soundness,
which is a feature we also integrate into the extract concurrent
refactoring. Another difference between this work and SUIF, ParaScope, Photran,
and TSF, is our focus on PGAS model languages as opposed to the more traditional
memory models of the procedural C and Fortran languages.
%
%A fair amount of work on transformations of skeletons, algorithmic patterns
%for defining stream-like programs, for parallel
%programming has been done in the FAN and Meta development
%frameworks~\cite{Bacci99, Aldinucci00}. Both FAN and Meta provide support for
%applying previously defined pattern transformations on the skeleton
%programs.

% \subsection{Concurrent Slicing}
% 
% Zhao~\cite{Zhao99} describes a method for determining a whole program slice for
% multi-threaded, concurrent Java programs using monitors for
% synchronization of data. To this end, an algorithm for creating a
% multithreaded dependence graph (MDG) is presented as an extension to
% the standard Object Oriented system dependence graph. By using a
% simple two-phase marking algorithm on the MDG, a program slice can be
% obtained. The analysis appears to be tailored to work on a
% multi-threaded shared memory program model, but may be modifiable to
% fit other types of concurrency architectures.
% 
% Chen and Xu\cite{Chen01} introduces the notion of object and class slicing as better
% ways to do program slicing for OO programs. To implement these new
% notions of slicing, a variant of program dependence graphs (PDGs) for
% methods is introduced which uses tagged dependence edges. A PDG for
% classes is then constructed by taking the union of the PDGs of the
% methods. While taking into account OO principles, this paper
% explicitly states that it is not concerned with concurrent behavior.
% 
% Chen, et al.,~\cite{Chen02} expands the work of \cite{Chen01, Zhao99}
% to define a dependence analysis over Ada 95's concurrent programming
% model. To do the analysis, they create two new types of CFG for
% concurrency and synchronization. They also define two Ada-specific
% types of dependence: task data dependence and synchronal
% dependence. Fundamental difference between Ada tasks and rendezvouz
% prevent the analysis from applying to X10 programs, though some of the
% concurrency analysis might be relevant.
% 
% Krinke~\cite{Krinke03} presents a context-sensitive concurrent slicing
% algorithm. Utilizing virtual inlining and a notion of interference
% dependence between threads, the slices can reach over thread
% boundaries and present a data dependency slice over the whole
% concurrent program. However, this approach elides certain concurrent
% programming constructs like synchronized blocks or dynamic activity
% creation.

% \subsection{To Be Categorized}

% The Illinois Concert System~\cite{Chien98} defined ICC++, an
% OO language with constructs for concurrency and distributed data, and a
% system of tools for its effective analysis and optimization of
% programs. However, very little support for
% code refactoring or transformation was developed for the Concert
% System.
% Closely related to concerns of X10, dynamic pointer
% alignment optimizations~\cite{Zhang97} attempt to optimize the
% parallelization of loops by arranging the tiling of loop iterations by
% location and aggregating data access. 

% The StreamIt Development Tool (SDT)~\cite{Kuo05} is an Eclipse IDE for
% advanced visual debugging support for the StreamIt
% language~\cite{StreamIt}. The language supports explicit parallel data
% streams via the {\em splitjoin} construct. SDT does a data flow
% analysis of the code to track data items as they enter and exit
% different parallel streams. The domain of streaming applications is
% particularly limited and this work does not address concerns of
% program transformation.
% 
% Solar-Lezama, et al,~\cite{Solar05, Solar06} discuss programming by
% sketching for bit- or integer-manipulation programs. To implement
% programs in this manner, a non-optimal program is created that has the
% desired output. A closer-to-optimal sketch of this program with
% explicit numeric holes is then written with the holes to be filled by
% the sketching synthesizer. With this technique, they have developed
% near-optimal programs that take advantage of bit-word structure and
% parallel bit manipulation. Sketching techinques might be advantageous
% for X10 code development to make optimal use of places -- especially
% with arrays -- but the work is too low level at this point to be
% realizable on an OO language.
% 
% Once transformations have been performed, skeletons can
% be implemented via optimized code from another language. Because this
% type of meta-language system does not allow explicit usage of
% synchronization or side-effects, transformations do not have to take
% such behavior into account. Furthermore, it is not clear how well
% these skeleton systems handle fine-grained control of concurrency.

% Allen, et al.,~\cite{Allen87} developed an automatic parallelization
% tool for {\tt DO} loops in Fortran. They determined that if all arrays
% in used in the loop could be privatized and there were no loop-carried
% dependencies between loop iterations, then each iteration could be
% performed on a separate processor. In researching the privatizability
% of arrays, they investigated code alignment and replication to handle
% some of the synchronization needed to deal with loop-carried
% dependencies between one iteration and the next. This work limited
% itself to attempting to parallelize whole loop bodies on individual
% processor instead of allowing for fine-grained parallel control, and
% while some local memory exists for each processor, depends on access
% to a shared global memory.
% 
% Hall, et al.,~\cite{Hall95} introduces automatic parallelization
% techniques for shared memory multiprocessor systems incorporating
% interprocedural analysis and granularity of loop bodies and array
% reductions for the SUIF compiler system~\cite{SUIF}. Using a selective
% procedure cloning, they avoid having to do loop unrolling and function
% inlining by doing a flow-sensitive analysis of procedure bodies and
% memoizing data-flow path information. To ensure highest loop
% granularity -- or lowest synchronization overhead -- they only
% parallelize the outermost loop for a set of parallelizable nested
% loops and suppress parallelization of array reductions if the cost of
% such parallelization outweigh sequential array reduction. They
% evaluate the success of these parallelizations by measuring
% parallelism coverage, granularity, and speedup on four processors.

% They include patterns for sequential, task-parallel, and
% data-parallel code. 
% Example transformations include {\em
% {\tt copy-scan} to {\tt copy-map}} and {\em {\tt map} function
% composition}. 

% Using both the static and dynamic dependence
% information, an interprocedural program slice of the statements
% affecting an examined loop is presented to the programmer. The
% programmer can then determine whether or not to parallelize the loop.
% They use a fairly standard interprocedural slicing algorithm to
% calculate the slice based on the determined dependencies. Because the
% SUIF system does not introduce parallel constructs to Fortran,
% concurrent thread execution is ignored by the static and dynamic
% analysis.

% Jrpm~\cite{Chen03} uses dynamic thread-level speculation to
% automatically parallelize Java loops. Building on top of the Hydra
% chip multiprocessor, which has hardware support for thread-level and
% data speculation, Jrpm profiles loops for dependency timing and buffer
% usage to determine if loop iterations can be parallelized. If the
% compiled statistics meet certain requirements, the Jrpm microJIT will
% recompile to create a speculative thread loop which spawns a new
% thread for every loop iteration. While some of the data dependency
% information generated could potentially be presented back to the user,
% this is not a practical approach to explicitly introduce parallelism
% in the code. The performance of this system is also tied to a
% particular multiprocessor architecture, and would not apply to systems
% that do not support hardware thread-level speculation.
% 
% Kamil and Yelick~\cite{Kamil05} developed a currency analysis for
% Titanium, a dialect of Java with explicit parallel {\em single
% program, multiple data} (SPMD) control. Titanium uses textually
% aligned barrier statements to control synchronization of parallel
% threads. Using these barriers, an analysis of the code is performed
% and a set of code phases is determined. An analysis to determine
% feasible call paths to and from procedures is also conducted. It is
% then determined that two statements may execute concurrently if they
% occur within the same code phase on a feasible path. The results of
% this analysis can then be used to find race conditions. While the
% analysis would be useful for determining loop carried dependencies in
% X10, the SPMD model is not compatible with X10's asynchronous activity
% model because of the lack of textually aligned barriers. Also, though
% this work has the capability to detect concurrency, the results do not
% provide insight where concurrency might be introduced.

% While this work is different from {\tt extract async/future} due to its
% loop-level parallelism, it was the first IDE which included parallel
% programming support with transformations. Also, it does not support {\em multi
% processor, distributed data} analysis.


