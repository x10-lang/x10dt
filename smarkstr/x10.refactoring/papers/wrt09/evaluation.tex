\section{Evaluation}

\subsection{Methods of Evaluating Transformed Code}

There are two vectors through which we can measure the effectiveness
of our extract concurrent transformation: running time and communication
overhead. If the running time of the transformed code is reduced and the amount
of additional communication is not made substantially worse, then the
refactoring would be considered a success.

In particular, comparing the performance of the transformation to a
program which only uses Java arrays -- which exist solely in one place
-- would not be a perfectly valid comparison in terms of running time
or interprocess communication. Distributed arrays inherently involve
at least some interprocess communication and, as a result, may require
more time to access or update elements of the array. As a result,
transformed code should be measured against loops similar to the one
seen in Figure~\ref{fig:async_loop}.

\begin{figure}
  \begin{code}
    Lo\=op (InductionVars $\ldots$)\{ \\
    \>  Block1 \\
    \>  Re\=sult = Exp1 op \\
    \>\> future(Target.dist[])\{f(Target[])\}.force() op\\
    \>\> Exp2; \\
    \>  Block2 \\
    \}
  \end{code}
\caption{\label{fig:async_loop} The basic candidate transformation
loop with explicit support for data distribution.}
\end{figure}

Most current X10 implementations do not have compiler optimizations that
significantly speed up concurrent data access, although some do support true
multiple processor data distribution and communication. Due to this, the time
measurements on both the basic asynchronous loop and the transformed
asynchronous loops will most likely exhibit much worse behavior than standard
Java. It is also possible that clock time between the basic and transformed
loops will not be accurate and comparisons on these results might be skewed
(e.g., the transformed loops might exhibit worse clock time because of
unoptimized thread spawning and thread communication). However, this is
simply a result of the current state of X10 implementation and not an
inherent shortcoming of the X10 language or other PGAS model
languages. At least one X10 implementation supports measurements that
separate out overheads associated with the current implementations from
those of the runtimes of X10 programs. It is with these tools that we hope
to effectively measure the costs and benefits associated with applying this
refactoring.

\subsection{A Formal Cost-Benefit Analysis of the Transformation}

In lieu of testing numbers, we present a more formal analysis of the
running time of the algorithm for best, worst, and average case scenarios. To
perform the analysis, we must first define a few variables. Let $m$ be the running time of
{\tt f(Target[])}, $n$ be the size of {\tt Target[]}, $C_{fut}$ be the overhead associated with starting a {\tt future}, $C_{for}$ be the overhead associated with calling {\tt force}, $p$ by the amount of available concurrency (i.e., number of
places or threads) and $p \leq n$, and $b$ be $O({\tt Block1}+{\tt
Exp1}+{\tt Exp2})+{\tt Block2})$.

For the code in Figure~\ref{fig:async_loop}, the running time would be

\vspace{-.1in}
\[O(n \cdot (b + C_{fut} + C_{for} + m))\].
\vspace{-.2in}

To analyze the {\tt future} transformation, we will break it down into
best case, worst case, and average case and ignore any thread overhead.

{\bf Best case} -- In the best case, the running time of the targeted
expression completely disappears. Thus, the running time in the best case is 

\vspace{-.1in}
\[\begin{array}{l}
O(n \cdot (b+C_{fut}) + n \cdot (b+C_{for})) \\ 
\vspace{.1in}
= O(n \cdot (2b + C_{fut} + C_{for})
\end{array}\]
\vspace{-.25in}

Thus the transformation is at least as good as the standard loop if $m
\leq b$.

{\bf Worst case} -- In the worst case, the full running time of the targeted
expression is observed every time at every {\tt force} expression. The running
time in the worst case is

\vspace{-.1in}
\[\begin{array}{l}
O(n \cdot (b+C_{fut}) + n \cdot (b+{C_for}+m)) \\
= O(n \cdot (2b + C_{fut} + C_{for} + m))
\end{array}\]
\vspace{-.15in}

In this case, there is no way for the transformed code
to match the performance of the standard loop unless $b = 0$. This
case is also equivalent to the case of having distributed data but
having no apparent concurrency.

{\bf Average case} -- In the average case analysis, $2 \leq p$, or the
worst case behavior is exhibited. We shall consider two subcases for
the average case analysis: with and without consideration of time
spent executing each loop when calculating the amount time of
evaluating {\tt f(Target[])}.

In the case of loop execution time not being factored, assume for the
sake of simplicity, but without loss of generality, that for every $p$
processes encountered, $m$ is accrued. Then the running time is 

\vspace{-.1in}
\[O(n \cdot (2b + C_{fut} + C_{for} + \frac{m}{p}))\]
\vspace{-.2in}

In this case, the transformation provides a performance boost if $m >
\frac{bp}{p-1}$. In the limit on $p$, this case is equivalent to the
best case.

If loop execution time is factored into the concurrent running time,
the analysis is slightly more complicated. First, the total running
time for the loop code that executes simultaneously with execution of
{\tt f(Target[])} is 

\[\begin{array}{l}
O(n \cdot (b + C_{fut}) - \frac{1}{2}b + n \cdot (b + C_{for}) -
\frac{1}{2}b) \\ 
= O(n \cdot ((2 - \frac{1}{n})b + C_{fut} + C_{for}))
\end{array}\]
\vspace{-.1in}

The total running time for the concurrent execution of {\tt f(Target[])},
assuming a similar perfect concurrent pipeline as in the previous
case, is $O(\frac{nm}{p} + p(b + C_{fut}))$. This is equivalent to the
best case when

\[m \leq ((2-\frac{p+1}{n})b + (1-\frac{p+1}{n})C_{fut}+C_{for})\]
\vspace{-.2in}

If the above inequality does not hold, running time is

\vspace{-.05in}
\[O(\frac{n}{p}((p-1)(2b+C_{fut}+C_{for})+2m)+(1+\frac{1}{p})(b+C_{fut}))\]
\vspace{-.1in}

This is at least as good as the basic loop if 

\vspace{-.05in}
\[m \geq (1 + \frac{p+1}{n(p-2)})b + \frac{n-p-1}{n(p-2)}C_{fut} -
\frac{1}{p-2}C_{for}\]
\vspace{-.1in}

In the limit of $p$, this is equivalent to the best case.

Except in the worst case scenario, this formal analysis indicates that the
extract concurrent refactoring \emph{should} provide beneficial results as long
as there are a large number of places and the data associated with the targeted
expression is relatively well distributed among the places. It will be
interesting to see how often this will be the case when applying the
refactoring to real X10 code.
